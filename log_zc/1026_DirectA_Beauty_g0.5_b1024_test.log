command line args [--zc 0.5] will not be used in RecBole
27 Oct 09:54    INFO  
General Hyper Parameters:
gpu_id = 2
use_gpu = True
seed = 0
state = INFO
reproducibility = True
data_path = dataset/Beauty
show_progress = False

Training Hyper Parameters:
checkpoint_dir = saved
epochs = 500
train_batch_size = 1024
learner = adam
learning_rate = 0.001
training_neg_sample_num = 0
training_neg_sample_distribution = uniform
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 1e-06
draw_loss_pic = False
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_setting = RO_RS,full
group_by_user = True
split_ratio = [0.8, 0.1, 0.1]
leave_one_num = 2
real_time_process = False
metrics = ['Recall', 'NDCG']
topk = [10, 20, 50]
valid_metric = NDCG@20
eval_batch_size = 4096
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'timestamp']}
unload_col = None
unused_col = None
additional_feat_suffix = None
lowest_val = None
highest_val = None
equal_val = None
not_equal_val = None
max_user_inter_num = None
min_user_inter_num = 5
max_item_inter_num = None
min_item_inter_num = 5
fields_in_same_space = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id

Other Hyper Parameters: 
valid_metric_bigger = True
BT = 0.1
bt = 0.001
embedding_size = 64
encoder = MF
gamma = 0.5
times = 1
witem = 0.1
wuser = 0.8
zc = 0.5
rm_dup_inter = None
filter_inter_by_user_or_item = True
SOURCE_ID_FIELD = source_id
TARGET_ID_FIELD = target_id
benchmark_filename = None
MODEL_TYPE = ModelType.GENERAL
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
device = cuda
train_neg_sample_args = {'strategy': 'none'}


27 Oct 09:54    INFO  Beauty
The number of users: 22364
Average actions of users: 8.876358270357287
The number of items: 12102
Average actions of items: 16.403768283612923
The number of inters: 198502
The sparsity of the dataset: 99.92665707018277%
Remain Fields: ['user_id', 'item_id', 'timestamp']
27 Oct 09:54    INFO  Build [GeneralDataLoader] for [train] with format [InputType.POINTWISE]
27 Oct 09:54    INFO  [train] No Negative Sampling
27 Oct 09:54    INFO  [train] batch_size = [1024], shuffle = [True]

27 Oct 09:54    INFO  Build [GeneralFullDataLoader] for [evaluation] with format [InputType.POINTWISE]
27 Oct 09:54    INFO  Evaluation Setting:
	Group by user_id
	Ordering: {'strategy': 'shuffle'}
	Splitting: {'strategy': 'by_ratio', 'ratios': [0.8, 0.1, 0.1]}
	Negative Sampling: {'strategy': 'full', 'distribution': 'uniform'}
27 Oct 09:54    INFO  [evaluation] batch_size = [4096], shuffle = [False]

27 Oct 09:54    WARNING  Batch size is changed to 12102.
27 Oct 09:54    WARNING  Batch size is changed to 12102.
{'BT': 0.1, 'bt': 0.001, 'embedding_size': 64, 'encoder': 'MF', 'gamma': None, 'times': 1, 'training_neg_sample_num': 0, 'witem': 0.1, 'wuser': 0.8, 'zc': 0.5}
this is encoder MF...
这是directau 的 WUBT 版本...0.5
27 Oct 09:54    INFO  DirectAU(
  (encoder): MFEncoder(
    (user_embedding): Embedding(22364, 64)
    (item_embedding): Embedding(12102, 64)
  )
  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  (projector): Sequential(
    (0): Linear(in_features=64, out_features=64, bias=False)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=64, out_features=64, bias=False)
    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=64, out_features=64, bias=False)
  )
)
Trainable parameters: 2218368
27 Oct 09:54    INFO  epoch 0 training [time: 2.76s, train loss: 0.1025]
27 Oct 09:54    INFO  epoch 0 evaluating [time: 9.30s, valid_score: 0.012300]
27 Oct 09:54    INFO  valid result: 
recall@10 : 0.0165    recall@20 : 0.0267    recall@50 : 0.0428    ndcg@10 : 0.0095    ndcg@20 : 0.0123    ndcg@50 : 0.0158    
27 Oct 09:54    INFO  Saving current best: saved/DirectAU-Oct-27-2023_09-54-09.pth
27 Oct 09:54    INFO  epoch 1 training [time: 2.71s, train loss: -0.5280]
Traceback (most recent call last):
  File "run_recbole.py", line 35, in <module>
    run_recbole(model=args.model, dataset=args.dataset, config_file_list=config_file_list)
  File "/data/danzhang/zhouchao/DirectAU/recbole/quick_start/quick_start.py", line 58, in run_recbole
    train_data, valid_data, saved=saved, show_progress=config['show_progress']
  File "/data/danzhang/zhouchao/DirectAU/recbole/trainer/trainer.py", line 316, in fit
    valid_score, valid_result = self._valid_epoch(valid_data, show_progress=show_progress)
  File "/data/danzhang/zhouchao/DirectAU/recbole/trainer/trainer.py", line 213, in _valid_epoch
    valid_result = self.evaluate(valid_data, load_best_model=False, show_progress=show_progress)
  File "/home/danzhang/miniconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/data/danzhang/zhouchao/DirectAU/recbole/trainer/trainer.py", line 427, in evaluate
    for batch_idx, batched_data in iter_data:
  File "/data/danzhang/zhouchao/DirectAU/recbole/data/dataloader/abstract_dataloader.py", line 94, in __next__
    return self._next_batch_data()
  File "/data/danzhang/zhouchao/DirectAU/recbole/data/dataloader/general_dataloader.py", line 266, in _next_batch_data
    cur_data = self._neg_sampling(user_df)
  File "/data/danzhang/zhouchao/DirectAU/recbole/data/dataloader/general_dataloader.py", line 282, in _neg_sampling
    swap_row = torch.cat([torch.full_like(swap, i) for i, swap in enumerate(swap_idx)])
KeyboardInterrupt
